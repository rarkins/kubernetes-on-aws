AWSTemplateFormatVersion: 2010-09-09
Description: Kubernetes spot.io Ocean stack

Mappings:
  Images:
    eu-central-1:
      MachineImage: "{{ .Cluster.ConfigItems.kuberuntu_image_v1_17 }}"

Resources:
  AutoScalingInstanceProfile:
    Properties:
      Path: /
      Roles:
      - !ImportValue "{{ .Cluster.ID }}:worker-iam-role"
    Type: "AWS::IAM::InstanceProfile"
  SpotinstOcean:
    Type: Custom::ocean
    Properties:
      ServiceToken: !Sub "arn:aws:lambda:${AWS::Region}:178579023202:function:spotinst-cloudformation"
      accessToken: "{{ .Cluster.ConfigItems.spotio_access_token }}"
      accountId: "{{ .Cluster.ConfigItems.spotio_account_id }}"
      autoTag: true
      updatePolicy:
        # TODO: configure this
        shouldUpdateTargetCapacity: false
        shouldRoll: "true"
        rollConfig:
          roll:
            batchSizePercentage: "25"
      # API Docs: https://help.spot.io/spotinst-api/ocean/ocean-cloud-api/ocean-for-aws/create-2/
      ocean:
        name: "{{ .Cluster.Alias }}"
        controllerClusterId: "{{ .Cluster.LocalID }}"
        region: !Ref AWS::Region
        autoScaler:
          isEnabled: true
          # cooldown: 180 # disabled to try out faster scaledown
          # maximum resources which can be allocated to the cluster
          # Use very high values as we have the limit set via the
          # NodePool.MaxSize
          resourceLimits:
            maxMemoryGib: 1500000
            maxVCpu: 75000
          down:
            evaluationPeriods: 3
          headroom: # disable headroom/preprovisioned instances
            cpuPerUnit: 0
            memoryPerUnit: 0
            numOfUnits: 0
          isAutoConfig: false
        capacity:
          minimum: {{ .NodePool.MinSize }}
          maximum: {{ .NodePool.MaxSize }}
          target: 0 # default target (should just be zero)
        strategy:
          spotPercentage: {{ .Cluster.ConfigItems.spotio_ocean_spot_percentage }}
          fallbackToOd: {{ .Cluster.ConfigItems.spotio_ocean_fallback_to_ondemand }}
          utilizeReservedInstances: {{ .Cluster.ConfigItems.spotio_ocean_utilize_reserved_instances }}
        compute:
          subnetIds:
          {{ with $values := .Values }}
          {{ range $az := $values.availability_zones }}
            - "{{ index $values.subnets $az }}"
          {{ end }}
          {{ end }}
          instanceTypes:
            whitelist:
            {{ range $type := .NodePool.InstanceTypes }}
              - "{{ $type }}"
            {{ end }}
          launchSpecification:
            tags:
            - tagKey: kubernetes.io/cluster/{{ .Cluster.ID }}
              tagValue: owned
            # TODO:
            - tagKey: Name
              tagValue: "SHOULD NOT SPAWN: {{ .NodePool.Name }} ({{ .Cluster.ID }})"
            - tagKey: spot.io/type
              tagValue: "ocean"
            associatePublicIpAddress: true
            imageId: !FindInMap
            - Images
            - !Ref "AWS::Region"
            - MachineImage
            userData: "{{ .UserData }}"
            securityGroupIds:
            - !ImportValue "{{ .Cluster.ID }}:worker-security-group"
            iamInstanceProfile:
              arn: !GetAtt
                - AutoScalingInstanceProfile
                - Arn
  SpotinstOceanLaunchSpec:
    Type: Custom::oceanLaunchSpec
    Properties:
      ServiceToken: !Sub "arn:aws:lambda:${AWS::Region}:178579023202:function:spotinst-cloudformation"
      accessToken: "{{ .Cluster.ConfigItems.spotio_access_token }}"
      accountId: "{{ .Cluster.ConfigItems.spotio_account_id }}"
      oceanLaunchSpec:
        oceanId: !Ref SpotinstOcean
        imageId: !FindInMap
        - Images
        - !Ref "AWS::Region"
        - MachineImage
        userData: "{{ .UserData }}"
        labels:
        - key: "spot.io"
          value: "true"
{{- if index .NodePool.ConfigItems "labels"}}
  {{- range split .NodePool.ConfigItems.labels ","}}
    {{- $label := split . "="}}
        - key: {{index $label 0}}
          value: {{index $label 1}}
  {{- end}}
{{end}}
        taints:
        - key: "spot.io"
          value: "true"
          effect: "NoSchedule"
# {{- if index .NodePool.ConfigItems "taints"}}
#   {{- range split .NodePool.ConfigItems.taints ","}}
#     {{- $taint := split . "="}}
#         # TODO: split value
#         - key: {{index $taint 0}}
#           value: {{index $taint 1}}
#   {{- end}}
# {{end}}
        tags:
          - tagKey: kubernetes.io/cluster/{{ .Cluster.ID }}
            tagValue: owned
          - tagKey: Name
            tagValue: "{{ .NodePool.Name }} ({{ .Cluster.ID }})"
            # TODO: evaluate how much of this we need?
          - tagKey: node.kubernetes.io/role
            tagValue: worker
          - tagKey: node.kubernetes.io/node-pool
            tagValue: {{ .NodePool.Name }}
          - tagKey: kubernetes.io/node-pool/profile
            tagValue: {{ .NodePool.Profile }}
          - tagKey: kubernetes.io/role/node-pool
            tagValue: "true"

          # TODO: do we want to run skipper on spot.io nodes?
          # only node pools without taints should be attached to Ingress Load balancer
# {{- if or (not (index .NodePool.ConfigItems "taints")) (eq (index .NodePool.ConfigItems "taints") "dedicated=skipper-ingress:NoSchedule") }}
#           - tagKey: zalando.org/ingress-enabled
#             tagValue: "true"
# {{- end }}
          - tagKey: spot.io/type
            tagValue: launchSpec
        autoScale:
          # disable headroom/preprovisioned instances
          headrooms: []
Outputs:
  OceanId:
    Description: The spot.io Ocean ID
    Value: !Ref SpotinstOcean
    Export:
      Name: "{{ .Cluster.ID}}:spotio-ocean-id"
